### 智能体落地场景
智能体系统与我们的现有系统，包括风控系统、模型系统并不是割裂开的一个新生成的体系，而是从原有体系演进而来的。

一个智能体系统主要包含以下三个重要模块[1]:

（1）规划模块（Planning）包括各种业务决策的知识，通常固定在智能体的链的定义中，也就是LangChain里面的一个chain，系统整体上是各种智能体的结合。

（2）存储模块（Memory）业务系统中的各种数据和元数据，可能存储在一种或者多种外部数据库中。

（3）工具模块（Tools）各种专有领域的业务模型和业务逻辑，包括各种图像模型、NLP 模型、风控的判别模型，以及风控系统的一些具体的业务逻辑等等。

#### 落地角度

![image](https://github.com/user-attachments/assets/ae3f53a3-5966-47cd-bbc3-20363330a132)

具体落地分为两大类：

（1）针对 Tools 的强化第一类是针对 tools 的强化。比如针对某个具体的图像模型，优化其效能。可以利用大模型理解指令的能力，和它承载的对应语言的通识和泛化能力，来做数据增强和引导，来增强特定环节的专有模型。这就是针对 tools 的强化。

（2）针对 Planning 和 Memory 的强化第二个角度是针对 planning 和 memory 的强化。第二个方向的对象是人，希望从业务同学现有的繁琐的重复性工作中涉及的业务知识和决策抽取出来，固定在一个智能体的链中，构建相应的智能体角色。

在智能体以及大模型的概念提出之后，我们在做需求的时候，虽然具体落地仍是逐一实现，但是在落地之前，思考这些需求之间的相互关系，并不是以单个场景或者是单个模型的角度去思考，而是以一个角色的角度去思考。比如现在要做的是数据分析师角色的优化，或者是欺诈调查员角色的优化。

### 场景一（减少大量的人工打标）：
![image](https://github.com/user-attachments/assets/5c00ed32-1e37-4c68-b969-a147a41af004)

根据客服对话历史判别用户是否需要特殊干预。按照以前的做法，面对这个问题，模型团队首先需要积累数据或者标注数据，整个交付流程和迭代流程会非常冗长和低效。

引入大模型之后，不再需要十万级的样本，只需要少量人工标注的数据，大概几百到 1000 左右就可以了。减少大量的人工达标的工作量。
首先通过一个大模型 Agent 基于标注的数据生成候选提示词，就是我希望这个样本数据应该是怎么样的。

然后第二个 Agent 会对前面提到的这个 Agent 进行排序打分，选出一个比较好的 prompt 交给大模型去生成数据。大模型的特点就是它能泛化，但是比较慢，而慢在这里不是太大的问题，因为它需要的训练数据量只有十万条级别，也不是特别多，基于这样的样例数据，再去就可以做一个线上的推理模型（分类模型）。

可能有的同学问为什么不直接把这个大模型上线？

主要的原因是现在这个系统每天的吞吐量要求很高，如果要让大模型实现非常快速的响应，就难以避免延时。因此比较好的一个办法就是直接让它去生成数据，蒸馏数据，然后生成小模型来迭代业务系统相应的模块。

最终这个需求的人工标注量大幅减少，减少了 90%，模型交付时间显著缩短，而模型效果比原来提高 20%。最令业务方最满意的是标注量和交付时间的减少，这意味着整个系统更加敏捷，应对变化的效率更高。

[代码](https://github.com/YUTING0907/pythonTools/blob/main/llm/auto_generate_tag.py)

#### 总结：

原始流程中，业务提一个需求，要做 AI 模型，就需要大量的标注工作量，而且往往我们对于这个领域的理解没有办法注入到数据中。

但现在基于大模型，图像的特征与语言描述得以对齐，然后通过语言这个载体，就可以与业务方的期望进行对齐。这里利用了大模型承载的通识，用来生成训练数据；
还利用了大模型的指令理解能力，领域专家直接将他对这个 case 的理解，通过自然语言来引导大模型来注入领域理解


### 场景二（欺诈调查助手）：



第一个场景是反欺诈调查的 copilot，通过与欺诈调查员的对话来解决相关问题。利用 GraphRAG 技术

1.意图识别：通过固定意图类别匹配用户的输入。

首先进行意图识别，这里的意图基本上都是固定好的，可枚举的，第一个就是基于业务知识的一般问答，第二个是基于调查库表的简单查询，第三个是基于关联团伙的查询。意图识别完成之后，针对意图来做参数解析，然后进行查询。
这里的业务知识一般都是以自由文档的方式存储在 RAG 的向量库里面，业务库表在数仓中。
目前公司没有一个特别完备的数据血缘，所以很多数据血缘的信息实际上是放在领域文档里面的。
所以第一步可能会做一个简单的图关系的抽取，一般都是一个预置好的 prompt，比如一些表的信息和关联的信息，如果有的话就把它抽出来做一个简单的支撑。

2.参数解析：根据识别到的意图提取查询所需的参数。

3.查询执行：支持业务知识问答、简单库表查询和关联团伙查询。

4.图关系抽取：预置 prompt 提取领域文档中的表信息和关联关系。



![image](https://github.com/user-attachments/assets/7d6ce731-e704-4eed-b586-3c16c8e8fa9d)





### Reference
[1] Lilian Weng (2023, June 23).  LLM Powered Autonomous Agents  https://lilianweng.github.io/posts/2023-06-23-agent/
